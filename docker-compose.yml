version: "3.8"
services:
  api:
    build:
      dockerfile: ./Dockerfile
      context: .
      # target: development
    volumes:
      - .:/app
      - /app/node_modules
    # command: npm run start:dev
    depends_on: 
      - postgres
      - redis
      - es01
    env_file:
      - .env
    ports:
      - 8000:8000
    expose:
      - 8000
    networks:
      - postgres
  postgres:
    container_name: postgres_container
    image: postgres:latest
    ports:
      - "5432:5432"
    volumes:
      - ./postgres-data:/var/lib/postgresql/data
      - ./pgfile:/tmp
    env_file:
      - docker.env
    networks:
      - postgres
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5

  pgadmin:
    links:
      - postgres:postgres
    container_name: pgadmin_container
    image: dpage/pgadmin4
    ports:
      - "8080:80"
    volumes:
      - ./pgadmin-data:/var/lib/pgadmin
    env_file:
      - docker.env
    restart: unless-stopped
    depends_on: 
      - postgres
    networks:
      - postgres

  adminer:
    image: adminer
    restart: always
    depends_on:
      - postgres
    networks:
      - postgres
    ports:
      - 6060:9000
  redis:
    image: "redis:alpine"
    ports:
      - "6379:6379"
    volumes:
      - redis:/data

  redis-commander:
    image: rediscommander/redis-commander:latest
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - "8081:8081"
    depends_on:
      - redis

  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.9.1
    container_name: es01
    environment:
      - node.name:es01
      - cluster.name:es-docker-cluster
      - discovery.seed_hosts:es02,es03
      - cluster.initial_master_nodes:es01,es02,es03
      - bootstrap.memory_lock:true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - ELASTICSEARCH_PASSWORD:admin
    # mem_limit: 2000
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    networks:
      - postgres
  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.9.1
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    # mem_limit: 2000
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./data02:/usr/share/elasticsearch/data
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    networks:
      - postgres
  es03:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.9.1
    container_name: es03
    environment:
      - node.name=es03
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es02
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    # mem_limit: 2000
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./data03:/usr/share/elasticsearch/data
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    networks:
      - postgres
  kib01:
    image: docker.elastic.co/kibana/kibana:7.12.0
    container_name: kib01
    ports: 
      - 5601:5601
    environment:
      - ELASTICSEARCH_HOSTS=http://esOne:9200
    depends_on: 
      - es01
      - es02
      - es03
    links: 
      - es01
      - es02
      - es03
    networks:
      - postgres
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    ports:
      - '9090:9090'
    networks:
      - postgres

  grafana:
    image: grafana/grafana:latest
    container_name: grafana_container
    restart: on-failure
    links:
      - prometheus:prometheus
    volumes:
      - ./data/grafana:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=12345
      - GF_RENDERING_SERVER_URL=http://renderer:8081/render
      - GF_RENDERING_CALLBACK_URL=http://grafana:3000/
      - GF_LOG_FILTERS=rendering:debug
    ports:
      - 3000:3000
    expose:
      - 3000
    networks:
      - postgres
  renderer:
    image: grafana/grafana-image-renderer:latest
    restart: on-failure
    container_name: grafana-image-renderer
    expose:
      - "8081"
    environment:
      ENABLE_METRICS: "true"
    networks:
      - postgres
    logging:
      driver: fluentd
      options:
        fluentd-address: host.docker.internal:24224
        tag: renderer

  fluent-bit:
    hostname: fluentd
    build:
      context: ./fluent-bit
      dockerfile: Dockerfile
    container_name: fluent-bit
    environment:
      - LOKI_URL=http://loki:3100/loki/api/v1/push
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    networks:
      - postgres

  loki:
    image: grafana/loki:latest
    restart: on-failure
    container_name: loki
    expose:
      - "3100"
    networks:
      - postgres
    logging:
      driver: fluentd
      options:
        fluentd-address: host.docker.internal:24224
        tag: loki
volumes:
  data01:
    driver: local
  data02:
    driver: local
  data03:
    driver: local
  postgres-data:
  pgadmin-data:

  redis:
    driver: local

networks:
  postgres:
    driver: bridge
  elastic:
    driver: bridge